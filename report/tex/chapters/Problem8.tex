\chapter{Unconstrained MPC}

1. Implement a function for design of an Unconstrained MPC based on discrete-time state
space models. You should explain in the report how your Matlab function work and its
theoretical background.

2. Design unconstrained MPC for the models identified in Problem 4 and Problem 5.

3. Implement and discuss a compute and prediction function for this MPC.

This section describes the unconstrained linear MPC regulator used for the Modified Four Tank System, based on a discrete-time linear state-space model. The purpose is to compute, at each sample time, an optimal future input sequence that steers the predicted outputs (tank levels) toward their references while regularizing both input magnitudes and input moves. The controller is receding-horizon: only the first input in the optimal sequence is applied, and the optimization is repeated at the next sample using updated state estimates.

\section{Discrete-time prediction model}

We assume a discrete-time linear model on deviation variables around a steady state,
\begin{align}
x_{k+1} &= A x_k + B u_k + E d_k, \\
y_k &= C_y x_k, \\
z_k &= C x_k,
\end{align}
where $x_k \in \mathbb{R}^{n_x}$ is the state, $u_k \in \mathbb{R}^{n_u}$ is the manipulated input (pump flows $F_1, F_2$), $d_k$ represents disturbances (e.g.\ unmeasured inflows $F_3,F_4$ if included in the linear model), $y_k$ is the measured output, and $z_k$ is the controlled output.

At time $k$, the controller uses the current state estimate (denoted $\hat{x}_{k|k}$) and (if applicable) a disturbance estimate $\hat{d}_{k|k}$ to predict future trajectories over a horizon of length $N$. For notational clarity, define predicted sequences
\[
\hat{x}_{k+j|k},\quad \hat{z}_{k+j|k},\quad \hat{u}_{k+j|k}, \qquad j=0,1,\dots
\]
generated by repeated simulation of the discrete model under a candidate input sequence.

\section{Stacked prediction over a finite horizon}

Let the decision variable be the stacked input vector
\[
U_k \;=\; \begin{bmatrix}
\hat{u}_{k|k} \\
\hat{u}_{k+1|k} \\
\vdots \\
\hat{u}_{k+N-1|k}
\end{bmatrix} \in \mathbb{R}^{N n_u}.
\]
Using the linear model, the stacked predicted controlled outputs can be written in affine form
\begin{align}
Z_k &= \begin{bmatrix}
\hat{z}_{k+1|k}\\
\hat{z}_{k+2|k}\\
\vdots\\
\hat{z}_{k+N|k}
\end{bmatrix}
\;=\; b_k + \Gamma U_k,
\end{align}
where $b_k$ collects all terms due to the current estimated state (and any known/estimated disturbance signals), while $\Gamma$ is the dynamic prediction matrix built from $(A,B,C)$. Similarly, a stacked reference vector is defined as
\[
R_k \;=\; \begin{bmatrix}
r_{k+1}\\
r_{k+2}\\
\vdots\\
r_{k+N}
\end{bmatrix},
\]
where $r_{k+j}$ is the reference for $z$ at future step $k+j$.

\section{Quadratic objective: tracking, input usage, and move suppression}

The MPC objective is the sum of three quadratic terms:
\[
\phi \;=\; \phi_z + \phi_u + \phi_{\Delta u}.
\]
Each term penalizes a different aspect of closed-loop behavior:

\paragraph{(i) Output tracking term.}
The tracking term penalizes predicted deviations between controlled outputs and references:
\begin{align}
\phi_z
&= \frac{1}{2}\sum_{j=1}^{N} \left\| W_z\big(\hat{z}_{k+j|k} - r_{k+j}\big)\right\|_2^2
= \frac{1}{2}\left\|\bar{W}_z\left(Z_k - R_k\right)\right\|_2^2,
\end{align}
where $W_z \succeq 0$ weights the components of $z$ (e.g.\ relative importance of Tank 1 vs.\ Tank 2 level control), and $\bar{W}_z = I_N \otimes W_z$ is the block-diagonal horizon extension.

\paragraph{(ii) Input magnitude regularization.}
To avoid unnecessarily large pump actions and to encode preferred operating points, the input penalty is
\begin{align}
\phi_u
&= \frac{1}{2}\sum_{j=0}^{N-1} \left\| W_u\big(\hat{u}_{k+j|k} - \bar{u}_{k+j}\big)\right\|_2^2
= \frac{1}{2}\left\|\bar{W}_u\left(U_k - \bar{U}_k\right)\right\|_2^2,
\end{align}
with $W_u \succeq 0$ and $\bar{W}_u = I_N \otimes W_u$. The sequence $\bar{U}_k$ is the desired (nominal) input trajectory, often constant at a steady-state input. In deviation-variable form, $\bar{U}_k$ is typically zero.

\paragraph{(iii) Input move suppression.}
To reduce aggressive actuation and produce smoother control actions, a move penalty is included:
\begin{align}
\phi_{\Delta u}
&= \frac{1}{2}\sum_{j=0}^{N-1} \left\| W_{\Delta u}\,\Delta \hat{u}_{k+j|k}\right\|_2^2,
\qquad
\Delta \hat{u}_{k+j|k} = \hat{u}_{k+j|k} - \hat{u}_{k+j-1|k}.
\end{align}
In stacked form this becomes
\begin{align}
\phi_{\Delta u}
&= \frac{1}{2}\left\|\bar{W}_{\Delta u}\left(\Lambda U_k - I_0 \hat{u}_{k-1|k}\right)\right\|_2^2,
\end{align}
where $\bar{W}_{\Delta u} = I_N \otimes W_{\Delta u}$, $\Lambda$ is a differencing operator that maps $U_k$ to stacked input increments, and $I_0 \hat{u}_{k-1|k}$ injects the previously applied input (known at time $k$) into the first increment.

\section{Quadratic program form and closed-form solution}

Because the prediction model is linear and the objective is quadratic, the total cost can be written as a convex quadratic function of $U_k$:
\begin{align}
\phi(U_k) = \frac{1}{2}U_k^\top H U_k + g^\top U_k + \rho,
\end{align}
where $H \succeq 0$ is the Hessian assembled from the three terms above, $g$ is the linear term that depends on $(\hat{x}_{k|k}, R_k, \bar{U}_k, \hat{u}_{k-1|k})$, and $\rho$ collects constants independent of $U_k$. In the unconstrained MPC setting, there are no bounds on $u$ or $z$, so the optimizer is obtained by first-order optimality:
\begin{align}
U_k^\star = -H^{-1}g,
\end{align}
assuming $H \succ 0$ (typically ensured by positive definite weighting on inputs and/or moves, and by appropriate horizon/observability properties).

\section{Receding-horizon control law}

The control action applied to the plant is the first element of the optimal sequence:
\[
u_k = \hat{u}_{k|k}^\star,
\]
while the remaining elements of $U_k^\star$ are discarded. At the next sampling time $k+1$, the state estimate is updated from measurements (via a static or dynamic Kalman filter, designed in Chapter~\ref{chap:6:state_estimation}), and a new optimization is solved using the shifted horizon.

This receding-horizon mechanism provides feedback in two ways:
\begin{itemize}
\item through the explicit use of the updated state estimate $\hat{x}_{k+1|k+1}$ in the prediction offset $b_{k+1}$,
\item and through continual re-optimization, which corrects for modeling errors, disturbances, and nonlinear plant behavior.
\end{itemize}

\section{Linear models}

Two linear model families are relevant:
\begin{itemize}
\item \textbf{Identified linear models (Chapter 4):} transfer-function/Markov-parameter based models derived from step-response experiments. These are typically converted to a discrete-time state-space realization to fit the MPC prediction framework.
\item \textbf{Linearized physical models (Chapter 5):} models obtained by linearizing the nonlinear mass-balance equations around a chosen steady state and discretizing with a chosen sampling time. These naturally yield $(A,B,C_y,C)$ and are well suited for prediction. 
\end{itemize}
For both model types, the unconstrained MPC setup is identical: only the numerical values of the prediction matrices ($\Gamma$, $b_k$) and therefore $H$ and $g$ change.

\section{Compute and prediction functionality (conceptual)}

In closed-loop use, the MPC regulator provides two core capabilities:

\paragraph{Compute (control move).}
Given $\hat{x}_{k|k}$ (and optionally $\hat{d}_{k|k}$), the future reference $R_k$, the nominal inputs $\bar{U}_k$, and the previous applied input $\hat{u}_{k-1|k}$, the controller constructs the quadratic cost $\phi(U_k)$ and returns the first component of $U_k^\star$. In the unconstrained case, this is a direct quadratic minimization with the unique solution $U_k^\star = -H^{-1}g$.

\paragraph{Predict (future trajectories).}
Using the same model and the optimal sequence $U_k^\star$, the controller generates predicted trajectories $\hat{x}_{k+j|k}$ and $\hat{z}_{k+j|k}$ for $j=1,\dots,N$. These predictions are used for analysis and reporting: they show how the controller expects tank levels and pump flows to evolve over the horizon, and they are essential for interpreting tuning choices (e.g.\ increasing $W_{\Delta u}$ yields smoother predicted inputs but typically slower predicted output convergence).

Together, these two functions define the unconstrained MPC closed-loop behavior: the \emph{compute} step produces the feedback control move, while the \emph{predict} step produces the internally consistent forecast that explains why that move is chosen.
